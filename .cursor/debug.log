{"sessionId": "debug-session", "runId": "gpt-init", "hypothesisId": "GPT_SERVICE_INIT", "location": "gpt_service.py:32", "message": "GPTService initialization", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false, "gpt_base_url_value": "https://druidservicegateway.comm.eu.druidplatform."}, "timestamp": 1768653198857}
{"sessionId": "debug-session", "runId": "db-init", "hypothesisId": "JOB_STATUS_SCHEMA", "location": "database.py:407", "message": "Checking job_status table", "data": {"table_exists": true}, "timestamp": 1768653200821}
{"sessionId": "debug-session", "runId": "db-init", "hypothesisId": "JOB_STATUS_SCHEMA", "location": "database.py:415", "message": "job_id column check", "data": {"column_exists": true}, "timestamp": 1768653200886}
{"sessionId": "debug-session", "runId": "gpt-init", "hypothesisId": "GPT_SERVICE_INIT", "location": "gpt_service.py:32", "message": "GPTService initialization", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false, "gpt_base_url_value": "https://druidservicegateway.comm.eu.druidplatform."}, "timestamp": 1768653210909}
{"sessionId": "debug-session", "runId": "db-init", "hypothesisId": "JOB_STATUS_SCHEMA", "location": "database.py:407", "message": "Checking job_status table", "data": {"table_exists": true}, "timestamp": 1768653213021}
{"sessionId": "debug-session", "runId": "db-init", "hypothesisId": "JOB_STATUS_SCHEMA", "location": "database.py:415", "message": "job_id column check", "data": {"column_exists": true}, "timestamp": 1768653213089}
{"sessionId": "debug-session", "runId": "gpt-init", "hypothesisId": "GPT_SERVICE_INIT", "location": "gpt_service.py:32", "message": "GPTService initialization", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false, "gpt_base_url_value": "https://druidservicegateway.comm.eu.druidplatform."}, "timestamp": 1768653222707}
{"sessionId": "debug-session", "runId": "db-init", "hypothesisId": "JOB_STATUS_SCHEMA", "location": "database.py:407", "message": "Checking job_status table", "data": {"table_exists": true}, "timestamp": 1768653224468}
{"sessionId": "debug-session", "runId": "db-init", "hypothesisId": "JOB_STATUS_SCHEMA", "location": "database.py:415", "message": "job_id column check", "data": {"column_exists": true}, "timestamp": 1768653224530}
{"sessionId": "debug-session", "runId": "upload-debug", "hypothesisId": "UPLOAD_ENDPOINT_ENTRY", "location": "main.py:940", "message": "Upload endpoint called", "data": {"filename": "[Salesforce] - How to create a new Account_720p.mp4", "name": null, "user_id": "504c497d-11b4-427a-b317-d5abdffe730e"}, "timestamp": 1768654281982}
{"sessionId": "debug-session", "runId": "upload-debug", "hypothesisId": "API_KEY_CHECK_UPLOAD", "location": "main.py:976", "message": "API key check in upload endpoint", "data": {"has_user_key": false, "has_system_key": false, "has_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "gpt_base_url_value": "https://druidservicegateway.comm.eu.druidplatform."}, "timestamp": 1768654282060}
{"sessionId": "debug-session", "runId": "upload-debug-v3", "hypothesisId": "VIDEO_FILE_NUMBER", "location": "video_file_number_service.py:66", "message": "Before conversion", "data": {"max_seq": "14", "max_seq_type": "Decimal", "row": "(Decimal('14'),)"}, "timestamp": 1768654282162}
{"sessionId": "debug-session", "runId": "upload-debug-v3", "hypothesisId": "VIDEO_FILE_NUMBER", "location": "video_file_number_service.py:80", "message": "Before format", "data": {"next_seq": 15, "next_seq_type": "int", "current_year": 2026}, "timestamp": 1768654282165}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "JOB_CREATE", "location": "main.py:1091", "message": "Creating job status", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16"}, "timestamp": 1768654282480}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "JOB_CREATE", "location": "main.py:1091", "message": "Job created successfully", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16"}, "timestamp": 1768654282779}
{"sessionId": "debug-session", "runId": "upload-service", "hypothesisId": "UPDATE_UPLOAD_ENTRY", "location": "video_upload_service.py:332", "message": "update_upload called", "data": {"upload_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "updates": {"status": "processing", "job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16"}, "user_id": null}, "timestamp": 1768654282779}
{"sessionId": "debug-session", "runId": "upload-service", "hypothesisId": "UPDATE_UPLOAD_FOUND", "location": "video_upload_service.py:343", "message": "Upload found, current status", "data": {"upload_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "current_status": "uploaded"}, "timestamp": 1768654282861}
{"sessionId": "debug-session", "runId": "upload-service", "hypothesisId": "UPDATE_UPLOAD_BEFORE_COMMIT", "location": "video_upload_service.py:350", "message": "Before commit, new status", "data": {"upload_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "new_status": "processing"}, "timestamp": 1768654282861}
{"sessionId": "debug-session", "runId": "upload-service", "hypothesisId": "UPDATE_UPLOAD_AFTER_COMMIT", "location": "video_upload_service.py:352", "message": "After commit and refresh, final status", "data": {"upload_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "final_status": "processing"}, "timestamp": 1768654283194}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "TASK_ADDED", "location": "main.py:1131", "message": "Adding background task", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "upload_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "file_path": "uploads\\0515a48b-9a69-4031-9ed9-e91a4c728a16_[Salesforce] - How to create a new Account_720p.mp4", "file_exists": true}, "timestamp": 1768654283264}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "TASK_ADDED", "location": "main.py:1132", "message": "Background task added successfully", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16"}, "timestamp": 1768654283267}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "TASK_EXECUTING", "location": "main.py:2441", "message": "Background task function executing", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "upload_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "file_path": "uploads\\0515a48b-9a69-4031-9ed9-e91a4c728a16_[Salesforce] - How to create a new Account_720p.mp4", "file_exists": true}, "timestamp": 1768654284488}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "API_KEY_CHECK", "location": "main.py:2447", "message": "API key check result", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "has_user_key": false, "has_system_key": false, "has_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true}, "timestamp": 1768654284662}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "JOB_STATUS_UPDATE", "location": "main.py:2472", "message": "Updating job status to processing", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16"}, "timestamp": 1768654284664}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "JOB_STATUS_UPDATE", "location": "main.py:2488", "message": "Job status update successful", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16"}, "timestamp": 1768654285053}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "SERVICE_INIT", "location": "main.py:2491", "message": "Initializing VideoProcessingService", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16"}, "timestamp": 1768654285055}
{"sessionId": "debug-session", "runId": "gpt-init", "hypothesisId": "GPT_SERVICE_INIT", "location": "gpt_service.py:32", "message": "GPTService initialization", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false, "gpt_base_url_value": "https://druidservicegateway.comm.eu.druidplatform."}, "timestamp": 1768654285057}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "SERVICE_INIT", "location": "main.py:2493", "message": "VideoProcessingService initialized", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16"}, "timestamp": 1768654285062}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "PROCESSING_START", "location": "main.py:2573", "message": "Starting process_video_complete", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "file_path": "uploads\\0515a48b-9a69-4031-9ed9-e91a4c728a16_[Salesforce] - How to create a new Account_720p.mp4"}, "timestamp": 1768654285065}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "PROCESS_VIDEO_COMPLETE_ENTRY", "location": "video_processing_service.py:630", "message": "process_video_complete function entry", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "video_path": "uploads\\0515a48b-9a69-4031-9ed9-e91a4c728a16_[Salesforce] - How to create a new Account_720p.mp4", "frames_dir": "frames", "audio_dir": "audio"}, "timestamp": 1768654285067}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "EXTRACT_AUDIO_ENTRY", "location": "video_processing_service.py:37", "message": "extract_audio function entry", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "video_path": "uploads\\0515a48b-9a69-4031-9ed9-e91a4c728a16_[Salesforce] - How to create a new Account_720p.mp4", "audio_dir": "audio"}, "timestamp": 1768654285069}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "EXTRACT_AUDIO_BEFORE", "location": "video_processing_service.py:98", "message": "Before calling extract_audio_async", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4"}, "timestamp": 1768654285416}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "EXTRACT_AUDIO_AFTER", "location": "video_processing_service.py:104", "message": "After extract_audio_async", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "audio_path": "audio\\705a23ae-ab3f-417e-9937-aa6bc23863e4\\audio.mp3"}, "timestamp": 1768654286523}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "EXTRACT_AUDIO_EXIT", "location": "video_processing_service.py:177", "message": "extract_audio function exit", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "audio_path": "audio\\705a23ae-ab3f-417e-9937-aa6bc23863e4\\audio.mp3"}, "timestamp": 1768654287247}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "TRANSCRIBE_AUDIO_ENTRY", "location": "video_processing_service.py:195", "message": "transcribe_audio function entry", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "audio_path": "audio\\705a23ae-ab3f-417e-9937-aa6bc23863e4\\audio.mp3", "has_openai_client": false}, "timestamp": 1768654287247}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "EXTRACT_KEYFRAMES_ENTRY", "location": "video_processing_service.py:299", "message": "extract_keyframes function entry", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "video_path": "uploads\\0515a48b-9a69-4031-9ed9-e91a4c728a16_[Salesforce] - How to create a new Account_720p.mp4", "frames_dir": "frames"}, "timestamp": 1768654287995}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "EXTRACT_KEYFRAMES_BEFORE", "location": "video_processing_service.py:343", "message": "Before calling extract_frames_async", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "frames_per_second": 0.5}, "timestamp": 1768654288419}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "EXTRACT_KEYFRAMES_AFTER", "location": "video_processing_service.py:350", "message": "After extract_frames_async", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "frame_count": 31}, "timestamp": 1768654297570}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "EXTRACT_KEYFRAMES_EXIT", "location": "video_processing_service.py:377", "message": "extract_keyframes function exit", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "frame_count": 31}, "timestamp": 1768654297952}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "PROCESS_FRAMES_ENTRY", "location": "video_processing_service.py:392", "message": "process_frames_with_gpt_batch function entry", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "total_frames": 31, "batch_size": 10}, "timestamp": 1768654297952}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "REDUCE_BATCH_SIZE_VPS", "location": "video_processing_service.py:512", "message": "Reducing batch size for custom GPT in process_frames", "data": {"original_batch_size": 10, "effective_batch_size": 2}, "timestamp": 1768654297952}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 1, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654298294}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654298294}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654298294}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654298296}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654298296}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654298296}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654298296}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654298305}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654298305}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654310797}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654310809}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 1, "analyzed_count": 2}, "timestamp": 1768654310809}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 1, "frames_in_batch": 2, "total_processed": 2}, "timestamp": 1768654311462}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 2, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654311831}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654311831}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654311831}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654311831}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654311831}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654311835}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654311835}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654311838}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654311838}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654326133}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654326139}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 2, "analyzed_count": 2}, "timestamp": 1768654326139}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 2, "frames_in_batch": 2, "total_processed": 4}, "timestamp": 1768654326863}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 3, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654327219}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654327227}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654327227}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654327227}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654327227}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654327227}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654327227}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654327227}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654327227}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654336778}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654336785}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 3, "analyzed_count": 2}, "timestamp": 1768654336788}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 3, "frames_in_batch": 2, "total_processed": 6}, "timestamp": 1768654337511}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 4, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654337895}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654337895}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654337895}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654337895}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654337895}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654337902}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654337903}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654337911}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654337911}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654348059}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654348059}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 4, "analyzed_count": 2}, "timestamp": 1768654348059}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 4, "frames_in_batch": 2, "total_processed": 8}, "timestamp": 1768654349152}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 5, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654349529}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654349529}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654349529}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654349529}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654349529}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654349529}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654349529}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654349539}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654349539}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654359939}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654359939}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 5, "analyzed_count": 2}, "timestamp": 1768654359955}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 5, "frames_in_batch": 2, "total_processed": 10}, "timestamp": 1768654360894}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 6, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654361308}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654361310}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654361311}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654361311}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654361311}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654361311}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654361313}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654361317}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654361317}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654374501}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654374511}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 6, "analyzed_count": 2}, "timestamp": 1768654374511}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 6, "frames_in_batch": 2, "total_processed": 12}, "timestamp": 1768654375132}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 7, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654375495}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654375495}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654375495}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654375495}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654375499}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654375499}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654375499}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654375506}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654375508}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654385993}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654385997}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 7, "analyzed_count": 2}, "timestamp": 1768654385998}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 7, "frames_in_batch": 2, "total_processed": 14}, "timestamp": 1768654386652}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 8, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654387031}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654387031}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654387031}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654387033}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654387033}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654387033}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654387034}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654387047}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654387048}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654396233}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654396233}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 8, "analyzed_count": 2}, "timestamp": 1768654396233}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 8, "frames_in_batch": 2, "total_processed": 16}, "timestamp": 1768654396895}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 9, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654397261}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654397261}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654397267}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654397267}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654397267}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654397271}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654397271}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654397285}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654397285}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654409616}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654409618}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 9, "analyzed_count": 2}, "timestamp": 1768654409620}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 9, "frames_in_batch": 2, "total_processed": 18}, "timestamp": 1768654410622}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 10, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654411012}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654411012}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654411012}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654411012}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654411017}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654411017}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654411017}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654411017}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654411017}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654422304}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654422304}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 10, "analyzed_count": 2}, "timestamp": 1768654422308}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 10, "frames_in_batch": 2, "total_processed": 20}, "timestamp": 1768654423081}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 11, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654423478}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654423478}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654423482}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654423482}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654423482}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654423482}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654423484}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654423486}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654423486}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654436149}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654436149}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 11, "analyzed_count": 2}, "timestamp": 1768654436149}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 11, "frames_in_batch": 2, "total_processed": 22}, "timestamp": 1768654436873}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 12, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654437270}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654437270}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654437270}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654437270}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654437270}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654437270}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654437270}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654437278}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654437278}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654450392}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654450392}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 12, "analyzed_count": 2}, "timestamp": 1768654450402}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 12, "frames_in_batch": 2, "total_processed": 24}, "timestamp": 1768654451191}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 13, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654451562}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654451562}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654451562}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654451564}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654451564}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654451564}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654451565}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654451568}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654451569}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654462940}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654462940}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 13, "analyzed_count": 2}, "timestamp": 1768654462940}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 13, "frames_in_batch": 2, "total_processed": 26}, "timestamp": 1768654463642}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 14, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654464012}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654464015}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654464015}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654464015}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654464015}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654464015}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654464015}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654464018}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654464018}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654473227}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654473227}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 14, "analyzed_count": 2}, "timestamp": 1768654473235}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 14, "frames_in_batch": 2, "total_processed": 28}, "timestamp": 1768654473981}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 15, "batch_size": 2, "gpt_batch_size": 10}, "timestamp": 1768654474411}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654474414}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654474414}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654474414}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 2}, "timestamp": 1768654474414}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654474414}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 2, "use_custom_gpt": true}, "timestamp": 1768654474414}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 2, "image_count": 2}, "timestamp": 1768654474422}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654474422}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654486937}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 2, "result_count": 2}, "timestamp": 1768654486940}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 15, "analyzed_count": 2}, "timestamp": 1768654486940}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 15, "frames_in_batch": 2, "total_processed": 30}, "timestamp": 1768654487642}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_BEFORE", "location": "video_processing_service.py:459", "message": "Before calling batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 16, "batch_size": 1, "gpt_batch_size": 10}, "timestamp": 1768654487995}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BATCH_ANALYZE_CHECK", "location": "gpt_service.py:960", "message": "Checking GPT service configuration", "data": {"use_custom_gpt": true, "gpt_base_url": true, "gpt_bearer_token": true, "has_client": false}, "timestamp": 1768654487995}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "RUNTIME_CHECK", "location": "gpt_service.py:964", "message": "Runtime custom GPT check", "data": {"use_custom_gpt_from_settings": true, "current_use_custom_gpt": true, "settings_gpt_base_url": true, "settings_gpt_bearer_token": true}, "timestamp": 1768654487995}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "BEFORE_CLIENT_CHECK", "location": "gpt_service.py:973", "message": "Before client check", "data": {"use_custom_gpt": true, "will_check_openai": false}, "timestamp": 1768654487995}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "USING_CUSTOM_GPT", "location": "gpt_service.py:1005", "message": "Using custom GPT service - proceeding with batch analysis", "data": {"use_custom_gpt": true, "total_frames": 1}, "timestamp": 1768654487995}
{"sessionId": "debug-session", "runId": "gpt-batch-check", "hypothesisId": "REDUCE_BATCH_SIZE", "location": "gpt_service.py:1050", "message": "Reducing batch size for custom GPT", "data": {"original_batch_size": 2, "effective_batch_size": 2, "reason": "Custom GPT has payload size limits"}, "timestamp": 1768654487995}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_START", "location": "gpt_service.py:1051", "message": "Starting batch analysis", "data": {"batch_size": 1, "use_custom_gpt": true}, "timestamp": 1768654487995}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "USE_CUSTOM_GPT_BATCH", "location": "gpt_service.py:730", "message": "Using custom GPT for batch", "data": {"batch_size": 1, "image_count": 1}, "timestamp": 1768654488002}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_CALL", "location": "gpt_service.py:329", "message": "Calling custom GPT service", "data": {"base_url": "https://druidservicegateway.comm.eu.druidplatform.", "model": "gpt-4o-mini", "messages_count": 1}, "timestamp": 1768654488002}
{"sessionId": "debug-session", "runId": "gpt-custom-call", "hypothesisId": "CUSTOM_GPT_SUCCESS", "location": "gpt_service.py:350", "message": "Custom GPT service call successful", "data": {"status_code": 200, "has_choices": true, "choices_count": 1}, "timestamp": 1768654496665}
{"sessionId": "debug-session", "runId": "gpt-batch-analyze", "hypothesisId": "BATCH_COMPLETE", "location": "gpt_service.py:1056", "message": "Batch analysis completed", "data": {"batch_size": 1, "result_count": 1}, "timestamp": 1768654496666}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "GPT_BATCH_AFTER", "location": "video_processing_service.py:470", "message": "After batch_analyze_frames", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 16, "analyzed_count": 1}, "timestamp": 1768654496666}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BATCH_STORED", "location": "video_processing_service.py:600", "message": "Batch stored in database", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "batch_num": 16, "frames_in_batch": 1, "total_processed": 31}, "timestamp": 1768654497110}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "PROCESS_FRAMES_EXIT", "location": "video_processing_service.py:613", "message": "process_frames_with_gpt_batch function exit", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "total_frames": 31}, "timestamp": 1768654497125}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "PROCESS_VIDEO_COMPLETE_EXIT", "location": "video_processing_service.py:769", "message": "process_video_complete function exit", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "transcript_length": 0, "frames_analyzed": 31}, "timestamp": 1768654497468}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "BEFORE_STATUS_UPDATE", "location": "main.py:2658", "message": "Before updating video upload status to completed", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "upload_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4"}, "timestamp": 1768654497477}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "CALLING_UPDATE_STATUS", "location": "main.py:2663", "message": "Calling update_upload_status", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "upload_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "target_status": "completed"}, "timestamp": 1768654497576}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "STATUS_UPDATE_ERROR", "location": "main.py:2696", "message": "Failed to update video upload status", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "upload_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "error": "cannot access local variable 'VideoUploadService' where it is not associated with a value", "error_type": "UnboundLocalError"}, "timestamp": 1768654497584}
{"sessionId": "debug-session", "runId": "processing-debug", "hypothesisId": "STATUS_UPDATE_FALLBACK", "location": "main.py:2714", "message": "Video upload status updated via fallback", "data": {"job_id": "0515a48b-9a69-4031-9ed9-e91a4c728a16", "upload_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "video_id": "705a23ae-ab3f-417e-9937-aa6bc23863e4", "rows_affected": 0}, "timestamp": 1768654497867}
